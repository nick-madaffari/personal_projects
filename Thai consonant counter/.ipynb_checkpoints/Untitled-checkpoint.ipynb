{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set URL to get text from\n",
    "\n",
    "url = 'https://th.wikipedia.org/wiki/%E0%B8%81%E0%B8%A3%E0%B8%B8%E0%B8%87%E0%B9%80%E0%B8%97%E0%B8%9E%E0%B8%A1%E0%B8%AB%E0%B8%B2%E0%B8%99%E0%B8%84%E0%B8%A3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes URL of a Thai webpage as the arguemnt & returns a dictionary\n",
    "\n",
    "def cons_count(my_url):\n",
    "    \"\"\"Returns a dictionary of number of Thai consonants\n",
    "       in the paragraph <p> tags of any URL\"\"\"\n",
    "\n",
    "    # opening connection, grabbing page\n",
    "    uClient = uReq(my_url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "\n",
    "    # html parsing\n",
    "    page_soup = soup(page_html, 'html.parser')\n",
    "    p_tags = page_soup.findAll('p')\n",
    "\n",
    "    # initialize empty dictionary\n",
    "    char_dict = {}\n",
    "\n",
    "    # nested loop that counts consonants\n",
    "    for text in p_tags:\n",
    "        for char in text.text:\n",
    "            if char in char_dict:\n",
    "                char_dict[char] += 1\n",
    "            else:\n",
    "                char_dict[char] = 1\n",
    "\n",
    "    consonants = ['ก', 'ข', 'ค', 'ฃ', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ฃ', 'ซ', 'ณ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด',\n",
    "                  'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฟ', 'พ', 'ฝ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส',\n",
    "                  'ห', 'ฬ', 'อ', 'ฮ']\n",
    "\n",
    "    # filter out characters that are not Thai consonants\n",
    "    filt_char_dict = {}\n",
    "    for k, v in char_dict.items():\n",
    "        if k in consonants:\n",
    "            filt_char_dict.update({k: v})\n",
    "\n",
    "    # sort dictionary by value (consonant count)\n",
    "    filt_char_dict = {k: v for k, v in sorted(filt_char_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    return filt_char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ร: 2042\n",
      "น: 1892\n",
      "ก: 1307\n",
      "ง: 1257\n",
      "ม: 1206\n",
      "อ: 1051\n",
      "ท: 965\n",
      "ย: 867\n",
      "ด: 716\n",
      "ว: 661\n",
      "ล: 622\n",
      "ห: 598\n",
      "ส: 596\n",
      "ต: 595\n",
      "ป: 545\n",
      "พ: 537\n",
      "ค: 534\n",
      "บ: 508\n",
      "จ: 406\n",
      "ศ: 339\n"
     ]
    }
   ],
   "source": [
    "# print top 20 results of function call on Thai version of Wikipedia page about Bangkok\n",
    "\n",
    "result = cons_count(url)\n",
    "for k, v in list(result.items())[:20]:\n",
    "    print(k + ':', v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
